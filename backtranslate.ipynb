{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/marc/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.single_model.tar.gz from cache at /home/marc/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3\n",
      "| [en] dictionary: 42024 types\n",
      "| [de] dictionary: 42024 types\n",
      "Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_wmt_en_de_big', attention_dropout=0.1, bpe='fastbpe', bpe_codes='/home/marc/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3/bpecodes', bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, data='/home/marc/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3', ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:17406', distributed_port=-1, distributed_rank=0, distributed_world_size=2, dropout=0.2, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=8192, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, extra_data='', fix_batches_to_gpus=False, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, lazy_load=False, left_pad_source=False, left_pad_target=False, log_format='simple', log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3584, max_update=201800, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, momentum=0.99, moses_no_dash_splits=False, moses_no_escape=False, no_cross_attention=False, no_epoch_checkpoints=False, no_progress_bar=True, no_save=False, no_token_positional_embeddings=False, num_workers=0, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/checkpoint/edunov/20190403/wmt19en2de.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed20_lbsm0.1_size_sa1_upsample2//finetune1', save_interval=1, save_interval_updates=200, seed=2, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_lang='de', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer='moses', train_subset='train', update_freq=[1], upsample_primary=1, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/marc/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.single_model.tar.gz from cache at /home/marc/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9\n",
      "| [de] dictionary: 42024 types\n",
      "| [en] dictionary: 42024 types\n",
      "Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_wmt_en_de_big', attention_dropout=0.1, bpe='fastbpe', bpe_codes='/home/marc/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9/bpecodes', bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, data='/home/marc/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9', ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:12536', distributed_port=-1, distributed_rank=0, distributed_world_size=2, dropout=0.2, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=8192, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, extra_data='', fix_batches_to_gpus=False, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, lazy_load=False, left_pad_source=False, left_pad_target=False, log_format='simple', log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3584, max_update=200200, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, momentum=0.99, moses_no_dash_splits=False, moses_no_escape=False, no_cross_attention=False, no_epoch_checkpoints=False, no_progress_bar=True, no_save=False, no_token_positional_embeddings=False, num_workers=0, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/checkpoint/edunov/20190403/wmt19de2en.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed21_lbsm0.1_size_sa1_upsample4//finetune1', save_interval=1, save_interval_updates=200, seed=2, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, source_lang='de', target_lang='en', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer='moses', train_subset='train', update_freq=[1], upsample_primary=1, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)\n"
     ]
    }
   ],
   "source": [
    "en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "fr2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.de-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "en2fr.cuda();\n",
    "fr2en.cuda();\n",
    "#en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-ru.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "#fr2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.ru-en.single_model', tokenizer='moses', bpe='fastbpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en2fr.encode(secret_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, \\\n",
    "otherwise it could just be an interesting paper you've read. \\\n",
    "Please try to provide some insight from your understanding and please dont post things which are present in wiki. \\\n",
    "Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around).\"\n",
    "#paraphrase = fr2en.translate(en2fr.translate(phrase))\n",
    "#phrase=\"a man was caught allegedly trying to smuggle two pounds of cocaine worth $30,000 in pairs of sneakers at jfk airport earlier this month. on april 7, thenga adams, flying from guyana in south america was arrested after customs at jfk in new york searched the sneakers in his luggage. when customs opened the soles of the athletic shoes they found $30,000 worth of cocaine, say airport officials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_message = \"secret code here: blah blah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase2=\"Washington received his initial military training and command with the Virginia Regiment during the French and Indian War. He was later elected to the Virginia House of Burgesses and was named a delegate to the Continental Congress, where he was appointed Commanding General of the nation's Continental Army. Washington led American forces, allied with France, in the defeat of the British at Yorktown. Once victory for the United States was in hand in 1783, Washington resigned his commission.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrase=phrase2[:len(phrase2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = ((phrase +'\\n')*2)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase=\"Japanese researchers began studying transistors three months after they were invented at America’s Bell Labs in 1947. Japanese companies then used transistors and other electronic parts and components to produce radios, television sets, Sony Walkmans, video cassette recorders, and computers. As the yen appreciated by 60% following the 1985 Plaza Accord, Japanese companies lost competitiveness in final electronics goods and moved upstream in electronics value chains. They focused on exporting electronic parts and components and capital goods to producers of final electronics goods abroad. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1)\n",
      "0.80723227901597034396598919963441651035560389705909174432210841531253168655332591502345004513511938847097107542097500689424514285497290038079560840414092248269013689951104583396312985854592625400982797145843505859375\n",
      "was string\n",
      "0.2565777873298434\n",
      "31.290420282812015\n",
      "46.69792729340328\n",
      "102.51287121916285\n",
      "114 new bits encoded\n",
      "(0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1)\n",
      "0.22890377442750098813132987186577584855040367265216805472602921989189184159840806387364864349365234375\n",
      "was string\n",
      "0.2565777873298434\n",
      "11.92148055561207\n",
      "34.00436811848897\n",
      "63.90707132719591\n",
      "75 new bits encoded\n",
      "(1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1)\n",
      "0.77662293612957000732421875\n",
      "was string\n",
      "0.2565777873298434\n",
      "26.323584579312044\n",
      "48.87230480899217\n",
      "102.62632484247744\n",
      "123 new bits encoded\n",
      "()\n",
      "0\n",
      "was string\n",
      "0.2565777873298434\n",
      "11.453820402010555\n",
      "20.018363878128653\n",
      "30.23831185451338\n",
      "37 new bits encoded\n"
     ]
    }
   ],
   "source": [
    "from encode import encode_long_text, decode_long_text\n",
    "T = 1.05\n",
    "topp=25\n",
    "encoded_text = encode_long_text(phrase,secret_message,(en2fr,fr2en),temperature=T,sampling_topk=topp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese researchers began studying transistors three months after they were invented at America’s Bell Labs in 1947. Japanese companies then used transistors and other electronic parts and components to produce radios, television sets, Sony Walkmans, video cassette recorders, and computers. As the yen appreciated by 60% following the 1985 Plaza Accord, Japanese companies lost competitiveness in final electronics goods and moved upstream in electronics value chains. They focused on exporting electronic parts and components and capital goods to producers of final electronics goods abroad. \n",
      "Japanese researchers began studying transistors three months after they were invented at America’s Bell Labs in 1947. Japanese companies then used transistors and other electronic parts and components to produce radios, television sets, Sony Walkmans, video cassette recorders, and computers. As the yen appreciated by 60% following the 1985 Plaza Accord, Japanese companies lost competitiveness in final electronics goods and moved upstream in electronics value chains. They focused on exporting electronic parts and components and capital goods to producers of final electronics goods abroad. \n",
      "Japanese researchers began studying transistors three months after they were invented at America’s Bell Labs in 1947. Japanese companies then used transistors and other electronic parts and components to produce radios, television sets, Sony Walkmans, video cassette recorders, and computers. As the yen appreciated by 60% following the 1985 Plaza Accord, Japanese companies lost competitiveness in final electronics goods and moved upstream in electronics value chains. They focused on exporting electronic parts and components and capital goods to producers of final electronics goods abroad. \n",
      "Japanese researchers began studying transistors three months after they were invented at America’s Bell Labs in 1947. Japanese companies then used transistors and other electronic parts and components to produce radios, television sets, Sony Walkmans, video cassette recorders, and computers. As the yen appreciated by 60% following the 1985 Plaza Accord, Japanese companies lost competitiveness in final electronics goods and moved upstream in electronics value chains. They focused on exporting electronic parts and components and capital goods to producers of final electronics goods abroad. \n",
      "Three months after Japanese researchers invented transistors at American Bell Labs in 1947, they began research into transistors. Japanese companies used transistors and other electronic components in manufacturing radios, TVs, Sony Walkmans, video cassette recorders and computers. When Japanese companies regained 60% of the value value of Japanese goods under the 1985 Plaza agreement, they lost their competitive position and advanced into electronic value chains, focusing on exports of electronic components and capital goods to end-product manufacturers overseas.\n",
      "Three months after their invention at Bell Labs in 1947, Japanese researchers began studying transistors. Japanese companies used transistors and other electronic devices and components to make radioes, televisions, Sony Walkmans, cassette recorders and computers. As the yen appreciated 60 percent after the 1985 Plaza Accord, Japanese companies lost their competitiveness in end-user electronics and advanced into electronic value chains, focusing on exporting electronic components and investment goods to end-user electronic manufacturers abroad.\n",
      "Three months after it was invented by the American Bell Labs in 1947, Japanese researchers began searching for transistors, using transistors and other electronic devices and components to produce radios, television sets, Sony Walkmans, videocassette recorders, and computers; as the yen increased by 60% after the 1985 Plaza accord, Japanese enterprises lost competition in the world's end product business and entered electronic value chains, and focused on exporting electronic components and investment goods to manufacturers of end products.\n",
      "Three months after their invention in Bell Labs in 1947, Japanese researchers began to explore transistors. Japanese companies used transistors and other electronic components and components to make radios, televisions, Sony Walkmans, video cassette recorders and computers. When the yen appreciated by 60% after the Plaza Agreement of 1985, Japanese companies lost their competitiveness in the field of electronic end products and moved into electronic value chains, focusing on the export of electronic components and capital goods to manufacturers of electronic end products abroad.\n"
     ]
    }
   ],
   "source": [
    "print(phrase)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was not string\n",
      "0.2565777873298434\n",
      "31.290420282812015\n",
      "46.69792729340328\n",
      "102.51287121916285\n",
      "0.80723227901597034396598919963441649018696721786196225203042777373009844753682846770014823110372680144553965373808707253905011581082167999995832863208132818693569354602209758943245889519054171954201127480449051281192076275238530342150261258173379531583093503681104437124185831867630954077679835651086548024412981662497832822698608734339891280630507939445356131296813760534589841834338188849962062819056043055794684664570920461723587582091121652551221865061641849146170864614400425460053029028354280283\n",
      "114\n",
      "[1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "114 new bits decoded\n",
      "was not string\n",
      "0.2565777873298434\n",
      "11.92148055561207\n",
      "34.00436811848897\n",
      "63.90707132719591\n",
      "0.22890377442750098813132064063526827811920319800612611651737234046475300778066371060977130112713021980831025541137726289153748531774762434785824827922695449445990493285713728055772479677277046485494264675783553487934895578353305883013751696812048040363816873341486086851053782029800164072765833153942313688472895352519887241642430708511507714040928235991526577987112374346252956618435728896670805955613586702486738786638824314284012575343451070314111429287607149347596155493747409070041734147518299169\n",
      "75\n",
      "[0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "75 new bits decoded\n",
      "was not string\n",
      "0.2565777873298434\n",
      "26.323584579312044\n",
      "48.87230480899217\n",
      "102.62632484247744\n",
      "0.77662293612957000732421874999999999995257596857774669468213679838250557282629587462585462782761423197770463618951250537705929125197559037937870563671645013212800668056457786434036645451483995926259548214179493282786930031599041174346375053096965926848243761870717805260827566597613583796407447522454511414199643947162602227922831113787755870056562351727701599823617067020867519391424415774605453198336795122411192796417602169630313440648979398184061081851974111849081989737545960657103820137884988194\n",
      "123\n",
      "[1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "123 new bits decoded\n",
      "was not string\n",
      "0.2565777873298434\n",
      "11.453820402010555\n",
      "20.018363878128653\n",
      "30.23831185451338\n",
      "0E-511\n",
      "37\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "37 new bits decoded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'secret code hepe: blah bla\\xa8\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_long_text(phrase,encoded_text,(en2fr,fr2en),temperature=T,sampling_topk=topp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en2fr.translate(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encode import Decimal, decimal2bits,bits2decimal,base,bits2int,int2bits\n",
    "d1 = Decimal('0.20778125110744850590004884')#32250413654913337267813466519786740907669778999493760589788833572897402384953444511083205122484195357863600181003837781909474691125864702477157920999424577273722591771737069006440588722540474532949333400948001162175229533576264541788131529054570956110173424058199988816591447207779910109810433472510024271285397363152083018789481774392869402397106821984572418185185105275461507458270049806265382808223980531092492811166434156736308321061317615525316808120047829631265934')\n",
    "d2 = Decimal('0.2077812511074485059000488391280336')\n",
    "print(list(decimal2bits(d1,86)))\n",
    "print(list(decimal2bits(d2,86)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(base(d1.as_tuple().digits,10,2)[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.ceil(86*np.log(2)/np.log(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(d1.as_tuple().digits[:int(86*np.log(2)/np.log(10))-1]))\n",
    "print(str(d2.as_tuple().digits[:int(86*np.log(2)/np.log(10))-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int(d1.to_eng_string()[2:]))\n",
    "print(int(d2.to_eng_string()[2:]+'0'))\n",
    "print(bin(int(d1.to_eng_string()[2:]))[2:])\n",
    "print(bin(int(d2.to_eng_string()[2:]+'0'))[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bin(int(d1.to_eng_string()[2:][::-1]))[2:][::-1])\n",
    "print(bin(int(d2.to_eng_string()[2:][::-1]))[2:][::-1])\n",
    "print(int(d1.to_eng_string()[2:][::-1]))\n",
    "print(int(d2.to_eng_string()[2:][::-1]))\n",
    "print(bin(int(d1.to_eng_string()[2:]))[2:])\n",
    "print(bin(int(d2.to_eng_string()[2:]))[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base(d1.as_tuple().digits[::-1],10,2)[::-1][:30])\n",
    "print(base(d2.as_tuple().digits[::-1],10,2)[::-1][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = base(d1.as_tuple().digits[::-1],10,2)[::-1][:30]\n",
    "\n",
    "print(bin(int(d1.to_eng_string()[2:][::-1]))[2:])\n",
    "print(bin(int(d2.to_eng_string()[2:][::-1]))[2:])\n",
    "print(int(d1.to_eng_string()[2:][::-1])-int(d2.to_eng_string()[2:][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decimal('0.'+str(bits2int([int(i) for i in bin(int(d1.to_eng_string()[2:][::-1]))[2:][::-1]]))[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encode import generate_hidden,getcontext,bind\n",
    "from encode import getcontext\n",
    "#bind(en2fr,generate_hidden,'generate_hidden')\n",
    "#bind(fr2en,generate_hidden,'generate_hidden')\n",
    "getcontext().prec = 500\n",
    "# de_bin = en2de.generate_hidden(message=Decimal(0.5), tokens=en2de.encode(phrase), beam=1, sampling=True, sampling_topp=.6,temperature=.8)\n",
    "# de_sample = de_bin[0]['tokens']\n",
    "# en = de2en.translate(en2de.decode(de_sample))\n",
    "n = len(en2fr.encode(phrase))\n",
    "de_phrase = en2fr.translate(phrase,min_len=4*n//5)\n",
    "T = 1.5\n",
    "topp=10\n",
    "output = generate_hidden(fr2en,message = secret_message,tokens=fr2en.encode(de_phrase),\n",
    "                               beam=1, sampling=True, sampling_topk=topp,temperature=T,min_len=4*n//5)\n",
    "phrase_with_hidden = fr2en.decode(output[0]['tokens'])\n",
    "# fr_bpe = en2de.string(fr_sample)\n",
    "# fr_toks = en2de.remove_bpe(fr_bpe)\n",
    "# fr = en2de.detokenize(fr_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fr2en.encode(phrase_with_hidden)\n",
    "print(phrase)\n",
    "print('\\n')\n",
    "print(phrase_with_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = generate_hidden(fr2en,message = output[0]['tokens'],decode=True,tokens=fr2en.encode(de_phrase),\n",
    "                               beam=1, sampling=True, sampling_topk=topp,temperature=T,min_len=4*n//5)\n",
    "print('\\n')\n",
    "print('Decoded message:',decimal2text(output2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "from encode import decimal2text,text2decimal,base\n",
    "-1*float((-1*output2+text2decimal(secret_message)).ln())/np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output2-text2decimal(secret_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def text2decimal(text):\n",
    "#     compressed_text_data = zlib.compress(text.encode('utf-8'))#zlib.compress()\n",
    "#     message_decimal = Decimal('0.'+base(list(compressed_text_data)[::-1], 256, 10, string=True)[::-1])\n",
    "#     return message_decimal\n",
    "\n",
    "# def decimal2text(decimal):\n",
    "#     base10digits = decimal.as_tuple().digits[::-1]\n",
    "#     base256bytes = bytes(base(base10digits,10,256))[::-1]\n",
    "#     decompressed_text = lib.decompress(base256bytes)\n",
    "#     return bytes(decompressed_text)#.decode('utf-8')\n",
    "decimal2text(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=base(list(secret_message.encode('utf-8')[::-1]),256,10)[::-1][:90]\n",
    "b = output2.as_tuple().digits[:90]\n",
    "print(a)\n",
    "print(b)\n",
    "ap = base(a[::-1],10,256)[::-1]\n",
    "bp = base(b[::-1],10,256)[::-1]\n",
    "print(ap)\n",
    "print(bp)\n",
    "print(list(secret_message.encode('utf-8')))\n",
    "print(list(ap))\n",
    "print(bytes(list(ap)))\n",
    "#print(bytes(list(ap)).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encode import encode_long_text, decode_long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text2decimal(secret_message))\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encode import Decimal\n",
    "d = Decimal('0.1233')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal2text(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal2text(text2decimal('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_with_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(phrase_with_hidden.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes(phrase,'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1]).long().view(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decimal(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
