{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/marc/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt19.en-de.joined-dict.single_model.tar.gz from cache at /home/marc/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3\n",
      "| [en] dictionary: 42024 types\n",
      "| [de] dictionary: 42024 types\n",
      "Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_wmt_en_de_big', attention_dropout=0.1, bpe='fastbpe', bpe_codes='/home/marc/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3/bpecodes', bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, data='/home/marc/.cache/torch/pytorch_fairseq/81a0be5cbbf1c106320ef94681844d4594031c94c16b0475be11faa5a5120c48.63b093d59e7e0814ff799bb965ed4cbde30200b8c93a44bf8c1e5e98f5c54db3', ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:17406', distributed_port=-1, distributed_rank=0, distributed_world_size=2, dropout=0.2, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=8192, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, extra_data='', fix_batches_to_gpus=False, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, lazy_load=False, left_pad_source=False, left_pad_target=False, log_format='simple', log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3584, max_update=201800, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, momentum=0.99, moses_no_dash_splits=False, moses_no_escape=False, no_cross_attention=False, no_epoch_checkpoints=False, no_progress_bar=True, no_save=False, no_token_positional_embeddings=False, num_workers=0, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/checkpoint/edunov/20190403/wmt19en2de.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed20_lbsm0.1_size_sa1_upsample2//finetune1', save_interval=1, save_interval_updates=200, seed=2, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_lang='de', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer='moses', train_subset='train', update_freq=[1], upsample_primary=1, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/marc/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt19.de-en.joined-dict.single_model.tar.gz from cache at /home/marc/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9\n",
      "| [de] dictionary: 42024 types\n",
      "| [en] dictionary: 42024 types\n",
      "Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer_wmt_en_de_big', attention_dropout=0.1, bpe='fastbpe', bpe_codes='/home/marc/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9/bpecodes', bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, data='/home/marc/.cache/torch/pytorch_fairseq/f42bb1b72d293668a5c50d9589fd2f3cc27322e390b1ef4cf3fdcf625c0d2fd7.bf6e22453272c2cba218a5ccecd045f73e926c34c1d66c47c9b31233343820a9', ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:12536', distributed_port=-1, distributed_rank=0, distributed_world_size=2, dropout=0.2, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=8192, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, extra_data='', fix_batches_to_gpus=False, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, lazy_load=False, left_pad_source=False, left_pad_target=False, log_format='simple', log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=3584, max_update=200200, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, momentum=0.99, moses_no_dash_splits=False, moses_no_escape=False, no_cross_attention=False, no_epoch_checkpoints=False, no_progress_bar=True, no_save=False, no_token_positional_embeddings=False, num_workers=0, optimizer='adam', optimizer_overrides='{}', raw_text=False, relu_dropout=0.0, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/checkpoint/edunov/20190403/wmt19de2en.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed21_lbsm0.1_size_sa1_upsample4//finetune1', save_interval=1, save_interval_updates=200, seed=2, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, source_lang='de', target_lang='en', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer='moses', train_subset='train', update_freq=[1], upsample_primary=1, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0)\n"
     ]
    }
   ],
   "source": [
    "en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "fr2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.de-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "en2fr.cuda();\n",
    "fr2en.cuda();\n",
    "#en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-ru.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "#fr2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.ru-en.single_model', tokenizer='moses', bpe='fastbpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en2fr.encode(secret_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"This is a place to share machine learning research papers, journals, and articles that you're reading this week. If it relates to what you're researching, by all means elaborate and give us your insight, \\\n",
    "otherwise it could just be an interesting paper you've read. \\\n",
    "Please try to provide some insight from your understanding and please dont post things which are present in wiki. \\\n",
    "Preferably you should link the arxiv page (not the PDF, you can easily access the PDF from the summary page but not the other way around).\"\n",
    "#paraphrase = fr2en.translate(en2fr.translate(phrase))\n",
    "#phrase=\"a man was caught allegedly trying to smuggle two pounds of cocaine worth $30,000 in pairs of sneakers at jfk airport earlier this month. on april 7, thenga adams, flying from guyana in south america was arrested after customs at jfk in new york searched the sneakers in his luggage. when customs opened the soles of the athletic shoes they found $30,000 worth of cocaine, say airport officials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_message = \"secret code here: blah blah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase2=\"Washington received his initial military training and command with the Virginia Regiment during the French and Indian War. He was later elected to the Virginia House of Burgesses and was named a delegate to the Continental Congress, where he was appointed Commanding General of the nation's Continental Army. Washington led American forces, allied with France, in the defeat of the British at Yorktown. Once victory for the United States was in hand in 1783, Washington resigned his commission.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrase=phrase2[:len(phrase2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = ((phrase +'\\n')*2)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase=\"Japanese researchers began studying transistors three months after they were invented at America’s Bell Labs in 1947. Japanese companies then used transistors and other electronic parts and components to produce radios, television sets, Sony Walkmans, video cassette recorders, and computers. As the yen appreciated by 60% following the 1985 Plaza Accord, Japanese companies lost competitiveness in final electronics goods and moved upstream in electronics value chains. They focused on exporting electronic parts and components and capital goods to producers of final electronics goods abroad. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1)\n",
      "0.80723227901597034396598919963441651035560389705909174432210841531253168655332591502345004513511938847097107542097500689424514285497290038079560840414092248269013689951104583396312985854592625400982797145843505859375\n",
      "was string\n",
      "0.2565777873298434\n",
      "31.290420282812015\n",
      "46.69792729340328\n",
      "102.51287121916285\n",
      "114 new bits encoded\n"
     ]
    }
   ],
   "source": [
    "from encode import encode_long_text, decode_long_text\n",
    "T = 1.05\n",
    "topp=25#25\n",
    "encoded_text,_,otherlang = encode_long_text(phrase,secret_message,(en2fr,fr2en),temperature=T,sampling_topk=topp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m Japanische\u001b[1;m Forscher\u001b[1;31m begannen\u001b[1;m\u001b[1;31m 1947,\u001b[1;m\u001b[1;31m drei\u001b[1;m\u001b[1;31m Monate\u001b[1;m\u001b[1;31m nach\u001b[1;m\u001b[1;31m ihrer\u001b[1;m\u001b[1;31m Erfindung\u001b[1;m in den amerikanischen Bell Labs Transistoren\u001b[1;31m zu\u001b[1;m\u001b[1;31m untersuchen.\u001b[1;m Japanische Unternehmen verwendeten Transistoren und andere elektronische\u001b[1;31m Bauteile\u001b[1;m\u001b[1;31m und\u001b[1;m\u001b[1;31m Komponenten,\u001b[1;m\u001b[1;31m um\u001b[1;m Radios,\u001b[1;31m Fernseher,\u001b[1;m Sony Walkmans,\u001b[1;31m Videokassettenrecorder\u001b[1;m und\u001b[1;31m Computer\u001b[1;m\u001b[1;31m herzustellen.\u001b[1;m Als\u001b[1;31m der\u001b[1;m\u001b[1;31m Yen\u001b[1;m\u001b[1;31m nach\u001b[1;m\u001b[1;31m dem\u001b[1;m\u001b[1;31m Plaza-Abkommen\u001b[1;m von 1985\u001b[1;31m um\u001b[1;m 60%\u001b[1;31m aufwertete,\u001b[1;m verloren\u001b[1;31m japanische\u001b[1;m\u001b[1;31m Unternehmen\u001b[1;m ihre\u001b[1;31m Wettbewerbsfähigkeit\u001b[1;m\u001b[1;31m im\u001b[1;m\u001b[1;31m Bereich\u001b[1;m\u001b[1;31m elektronischer\u001b[1;m\u001b[1;31m Endprodukte\u001b[1;m und\u001b[1;31m rückten\u001b[1;m in elektronische Wertschöpfungsketten\u001b[1;31m vor.\u001b[1;m\u001b[1;31m Sie\u001b[1;m\u001b[1;31m konzentrierten\u001b[1;m sich auf den Export elektronischer Bauteile und Investitionsgüter an\u001b[1;31m Hersteller\u001b[1;m\u001b[1;31m elektronischer\u001b[1;m\u001b[1;31m Endprodukte\u001b[1;m\u001b[1;31m im\u001b[1;m\u001b[1;31m Ausland.\u001b[1;m\n",
      "\u001b[1;32m Drei\u001b[1;m\u001b[1;32m Monate\u001b[1;m\u001b[1;32m nachdem\u001b[1;m\u001b[1;32m japanische\u001b[1;m Forscher\u001b[1;32m 1947\u001b[1;m in den amerikanischen Bell Labs Transistoren\u001b[1;32m erfunden\u001b[1;m\u001b[1;32m hatten,\u001b[1;m\u001b[1;32m begannen\u001b[1;m\u001b[1;32m sie\u001b[1;m\u001b[1;32m mit\u001b[1;m\u001b[1;32m der\u001b[1;m\u001b[1;32m Erforschung\u001b[1;m\u001b[1;32m von\u001b[1;m\u001b[1;32m Transistoren.\u001b[1;m Japanische Unternehmen verwendeten Transistoren und andere elektronische\u001b[1;32m Komponenten\u001b[1;m\u001b[1;32m in\u001b[1;m\u001b[1;32m der\u001b[1;m\u001b[1;32m Produktion\u001b[1;m\u001b[1;32m von\u001b[1;m Radios,\u001b[1;32m Fernsehern,\u001b[1;m Sony Walkmans,\u001b[1;32m Videokassettenrecordern\u001b[1;m und\u001b[1;32m Computern.\u001b[1;m Als\u001b[1;32m japanische\u001b[1;m\u001b[1;32m Unternehmen\u001b[1;m\u001b[1;32m im\u001b[1;m\u001b[1;32m Rahmen\u001b[1;m\u001b[1;32m des\u001b[1;m\u001b[1;32m Plaza-Abkommens\u001b[1;m von 1985 60%\u001b[1;32m des\u001b[1;m\u001b[1;32m Wertes\u001b[1;m\u001b[1;32m japanischer\u001b[1;m\u001b[1;32m Waren\u001b[1;m\u001b[1;32m zurückgewannen,\u001b[1;m verloren\u001b[1;32m sie\u001b[1;m ihre\u001b[1;32m Wettbewerbsposition\u001b[1;m und\u001b[1;32m stiegen\u001b[1;m in elektronische Wertschöpfungsketten\u001b[1;32m auf,\u001b[1;m\u001b[1;32m wobei\u001b[1;m\u001b[1;32m sie\u001b[1;m sich auf den Export elektronischer Bauteile und Investitionsgüter an\u001b[1;32m Endprodukthersteller\u001b[1;m\u001b[1;32m in\u001b[1;m\u001b[1;32m Übersee\u001b[1;m\u001b[1;32m konzentrierten.\u001b[1;m\n"
     ]
    }
   ],
   "source": [
    "old_trans = en2fr.translate(phrase,beam=20,temperature=.8)\n",
    "new_trans = en2fr.translate(encoded_text,beam=20,temperature=.8)\n",
    "compare(old_trans,new_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Japanese researchers\u001b[1;31m began\u001b[1;m\u001b[1;31m studying\u001b[1;m transistors\u001b[1;31m three\u001b[1;m\u001b[1;31m months\u001b[1;m\u001b[1;31m after\u001b[1;m\u001b[1;31m they\u001b[1;m\u001b[1;31m were\u001b[1;m\u001b[1;31m invented\u001b[1;m at\u001b[1;31m America’s\u001b[1;m Bell Labs in\u001b[1;31m 1947.\u001b[1;m Japanese companies\u001b[1;31m then\u001b[1;m used transistors and other electronic\u001b[1;31m parts\u001b[1;m\u001b[1;31m and\u001b[1;m components\u001b[1;31m to\u001b[1;m\u001b[1;31m produce\u001b[1;m radios,\u001b[1;31m television\u001b[1;m\u001b[1;31m sets,\u001b[1;m Sony Walkmans, video cassette\u001b[1;31m recorders,\u001b[1;m and computers.\u001b[1;31m As\u001b[1;m the\u001b[1;31m yen\u001b[1;m\u001b[1;31m appreciated\u001b[1;m\u001b[1;31m by\u001b[1;m\u001b[1;31m 60%\u001b[1;m\u001b[1;31m following\u001b[1;m the 1985 Plaza\u001b[1;31m Accord,\u001b[1;m\u001b[1;31m Japanese\u001b[1;m\u001b[1;31m companies\u001b[1;m lost\u001b[1;31m competitiveness\u001b[1;m\u001b[1;31m in\u001b[1;m\u001b[1;31m final\u001b[1;m\u001b[1;31m electronics\u001b[1;m\u001b[1;31m goods\u001b[1;m and\u001b[1;31m moved\u001b[1;m\u001b[1;31m upstream\u001b[1;m\u001b[1;31m in\u001b[1;m\u001b[1;31m electronics\u001b[1;m value\u001b[1;31m chains.\u001b[1;m\u001b[1;31m They\u001b[1;m\u001b[1;31m focused\u001b[1;m on\u001b[1;31m exporting\u001b[1;m electronic\u001b[1;31m parts\u001b[1;m\u001b[1;31m and\u001b[1;m components and capital goods to\u001b[1;31m producers\u001b[1;m\u001b[1;31m of\u001b[1;m\u001b[1;31m final\u001b[1;m\u001b[1;31m electronics\u001b[1;m\u001b[1;31m goods\u001b[1;m\u001b[1;31m abroad.\u001b[1;m\u001b[1;31m \u001b[1;m\n",
      "\u001b[1;32m Three\u001b[1;m\u001b[1;32m months\u001b[1;m\u001b[1;32m after\u001b[1;m Japanese researchers\u001b[1;32m invented\u001b[1;m transistors at\u001b[1;32m American\u001b[1;m Bell Labs in\u001b[1;32m 1947,\u001b[1;m\u001b[1;32m they\u001b[1;m\u001b[1;32m began\u001b[1;m\u001b[1;32m research\u001b[1;m\u001b[1;32m into\u001b[1;m\u001b[1;32m transistors.\u001b[1;m Japanese companies used transistors and other electronic components\u001b[1;32m in\u001b[1;m\u001b[1;32m manufacturing\u001b[1;m radios,\u001b[1;32m TVs,\u001b[1;m Sony Walkmans, video cassette\u001b[1;32m recorders\u001b[1;m and computers.\u001b[1;32m When\u001b[1;m\u001b[1;32m Japanese\u001b[1;m\u001b[1;32m companies\u001b[1;m\u001b[1;32m regained\u001b[1;m\u001b[1;32m 60%\u001b[1;m\u001b[1;32m of\u001b[1;m the\u001b[1;32m value\u001b[1;m\u001b[1;32m value\u001b[1;m\u001b[1;32m of\u001b[1;m\u001b[1;32m Japanese\u001b[1;m\u001b[1;32m goods\u001b[1;m\u001b[1;32m under\u001b[1;m the 1985 Plaza\u001b[1;32m agreement,\u001b[1;m\u001b[1;32m they\u001b[1;m lost\u001b[1;32m their\u001b[1;m\u001b[1;32m competitive\u001b[1;m\u001b[1;32m position\u001b[1;m and\u001b[1;32m advanced\u001b[1;m\u001b[1;32m into\u001b[1;m\u001b[1;32m electronic\u001b[1;m value\u001b[1;32m chains,\u001b[1;m\u001b[1;32m focusing\u001b[1;m on\u001b[1;32m exports\u001b[1;m\u001b[1;32m of\u001b[1;m electronic components and capital goods to\u001b[1;32m end-product\u001b[1;m\u001b[1;32m manufacturers\u001b[1;m\u001b[1;32m overseas.\u001b[1;m\n"
     ]
    }
   ],
   "source": [
    "from encode import colorize\n",
    "import difflib\n",
    "import sys\n",
    "def token2color(token,added=True):\n",
    "    if token[0]=='?':\n",
    "        return ''\n",
    "    elif token[0]=='+':\n",
    "        return colorize(token[1:],'green') if added else ''\n",
    "    elif token[0]=='-':\n",
    "        return '' if added else colorize(token[1:],'red')\n",
    "    else:\n",
    "        return token[1:]\n",
    "def compare(stra,strb):\n",
    "    diff = list(difflib.Differ().compare(stra.split(' '),strb.split(' ')))\n",
    "    print(''.join([token2color(tok,False) for tok in diff]))\n",
    "    print(''.join([token2color(tok) for tok in diff]))\n",
    "    \n",
    "compare(phrase,encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(en2fr)\n",
    "\n",
    "# diff = list(difflib.Differ().compare(en2fr.apply_bpe(en2fr.tokenize(phrase)).split(' '),en2fr.apply_bpe(en2fr.tokenize(encoded_text)).split(' ')))\n",
    "# print(en2fr.detokenize(en2fr.remove_bpe(''.join([token2color(tok,False) for tok in diff]))))\n",
    "# print(''.join([token2color(tok) for tok in diff]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_long_text(phrase,encoded_text,(en2fr,fr2en),temperature=T,sampling_topk=topp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en2fr.translate(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encode import Decimal, decimal2bits,bits2decimal,base,bits2int,int2bits\n",
    "d1 = Decimal('0.20778125110744850590004884')#32250413654913337267813466519786740907669778999493760589788833572897402384953444511083205122484195357863600181003837781909474691125864702477157920999424577273722591771737069006440588722540474532949333400948001162175229533576264541788131529054570956110173424058199988816591447207779910109810433472510024271285397363152083018789481774392869402397106821984572418185185105275461507458270049806265382808223980531092492811166434156736308321061317615525316808120047829631265934')\n",
    "d2 = Decimal('0.2077812511074485059000488391280336')\n",
    "print(list(decimal2bits(d1,86)))\n",
    "print(list(decimal2bits(d2,86)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(base(d1.as_tuple().digits,10,2)[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.ceil(86*np.log(2)/np.log(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(d1.as_tuple().digits[:int(86*np.log(2)/np.log(10))-1]))\n",
    "print(str(d2.as_tuple().digits[:int(86*np.log(2)/np.log(10))-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int(d1.to_eng_string()[2:]))\n",
    "print(int(d2.to_eng_string()[2:]+'0'))\n",
    "print(bin(int(d1.to_eng_string()[2:]))[2:])\n",
    "print(bin(int(d2.to_eng_string()[2:]+'0'))[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bin(int(d1.to_eng_string()[2:][::-1]))[2:][::-1])\n",
    "print(bin(int(d2.to_eng_string()[2:][::-1]))[2:][::-1])\n",
    "print(int(d1.to_eng_string()[2:][::-1]))\n",
    "print(int(d2.to_eng_string()[2:][::-1]))\n",
    "print(bin(int(d1.to_eng_string()[2:]))[2:])\n",
    "print(bin(int(d2.to_eng_string()[2:]))[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base(d1.as_tuple().digits[::-1],10,2)[::-1][:30])\n",
    "print(base(d2.as_tuple().digits[::-1],10,2)[::-1][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = base(d1.as_tuple().digits[::-1],10,2)[::-1][:30]\n",
    "\n",
    "print(bin(int(d1.to_eng_string()[2:][::-1]))[2:])\n",
    "print(bin(int(d2.to_eng_string()[2:][::-1]))[2:])\n",
    "print(int(d1.to_eng_string()[2:][::-1])-int(d2.to_eng_string()[2:][::-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decimal('0.'+str(bits2int([int(i) for i in bin(int(d1.to_eng_string()[2:][::-1]))[2:][::-1]]))[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encode import generate_hidden,getcontext,bind\n",
    "from encode import getcontext\n",
    "#bind(en2fr,generate_hidden,'generate_hidden')\n",
    "#bind(fr2en,generate_hidden,'generate_hidden')\n",
    "getcontext().prec = 500\n",
    "# de_bin = en2de.generate_hidden(message=Decimal(0.5), tokens=en2de.encode(phrase), beam=1, sampling=True, sampling_topp=.6,temperature=.8)\n",
    "# de_sample = de_bin[0]['tokens']\n",
    "# en = de2en.translate(en2de.decode(de_sample))\n",
    "n = len(en2fr.encode(phrase))\n",
    "de_phrase = en2fr.translate(phrase,min_len=4*n//5)\n",
    "T = 1.5\n",
    "topp=10\n",
    "output = generate_hidden(fr2en,message = secret_message,tokens=fr2en.encode(de_phrase),\n",
    "                               beam=1, sampling=True, sampling_topk=topp,temperature=T,min_len=4*n//5)\n",
    "phrase_with_hidden = fr2en.decode(output[0]['tokens'])\n",
    "# fr_bpe = en2de.string(fr_sample)\n",
    "# fr_toks = en2de.remove_bpe(fr_bpe)\n",
    "# fr = en2de.detokenize(fr_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fr2en.encode(phrase_with_hidden)\n",
    "print(phrase)\n",
    "print('\\n')\n",
    "print(phrase_with_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = generate_hidden(fr2en,message = output[0]['tokens'],decode=True,tokens=fr2en.encode(de_phrase),\n",
    "                               beam=1, sampling=True, sampling_topk=topp,temperature=T,min_len=4*n//5)\n",
    "print('\\n')\n",
    "print('Decoded message:',decimal2text(output2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "from encode import decimal2text,text2decimal,base\n",
    "-1*float((-1*output2+text2decimal(secret_message)).ln())/np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output2-text2decimal(secret_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def text2decimal(text):\n",
    "#     compressed_text_data = zlib.compress(text.encode('utf-8'))#zlib.compress()\n",
    "#     message_decimal = Decimal('0.'+base(list(compressed_text_data)[::-1], 256, 10, string=True)[::-1])\n",
    "#     return message_decimal\n",
    "\n",
    "# def decimal2text(decimal):\n",
    "#     base10digits = decimal.as_tuple().digits[::-1]\n",
    "#     base256bytes = bytes(base(base10digits,10,256))[::-1]\n",
    "#     decompressed_text = lib.decompress(base256bytes)\n",
    "#     return bytes(decompressed_text)#.decode('utf-8')\n",
    "decimal2text(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=base(list(secret_message.encode('utf-8')[::-1]),256,10)[::-1][:90]\n",
    "b = output2.as_tuple().digits[:90]\n",
    "print(a)\n",
    "print(b)\n",
    "ap = base(a[::-1],10,256)[::-1]\n",
    "bp = base(b[::-1],10,256)[::-1]\n",
    "print(ap)\n",
    "print(bp)\n",
    "print(list(secret_message.encode('utf-8')))\n",
    "print(list(ap))\n",
    "print(bytes(list(ap)))\n",
    "#print(bytes(list(ap)).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encode import encode_long_text, decode_long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text2decimal(secret_message))\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encode import Decimal\n",
    "d = Decimal('0.1233')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal2text(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal2text(text2decimal('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_with_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(phrase_with_hidden.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes(phrase,'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1]).long().view(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decimal(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
